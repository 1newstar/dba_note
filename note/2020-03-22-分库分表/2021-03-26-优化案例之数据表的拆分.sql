优化案例之数据表的拆分：
	某个游戏上线2个多月，3000多W行记录
	数据量： 保留3个月的数据，一共有25个字段，物理大小： 40G，实际数据15G，索引25G
	
	遇到的瓶颈：
		1. 后期这个表会越来越大，而且这个表变更相对较频繁，使用pt-osc加列，虽然是在业务低峰期操作，但是耗时比较久，偶尔变更还可以接受。
		2. 报表查询速度慢;
	
    游戏的战绩详情表， 建有6个索引，其中5个联合索引 ，1个单列索引，都是业务需要用到的，
	
	第一阶段
		该战绩详情表，有两种类型的数据，一种是机器人的，另一种是真人的，实际上真人的数据和机器人的数据并不会一起做查询，并且查询机器人的数据只需要1个索引 ，因此该大表的优化方案是 把机器人和真人的数据拆分成两个表，机器人表只需要建立2个独立索引
		最后的数据量：27G，节省了13G的磁盘空间。
			真人表物理大小12G，数据和索引分别是6G
			机器人表物理大小 15G，数据14G，索引1G
		  数据表的拆分是在线做的，通过 pt-archiver工具来做。
	
	第二阶段
    
        把机器人战绩表的数据用MongoDB来存储，其它相对独立，也就是不需要跨表查询的数据，也是用MongoDB来存储数据，比如游戏日志等。
        真人战绩表、积分更新表等、按日期分表，每天1个表，表的自增ID步长为1亿。
		 
		通过适当的拆分，分库和分表，提高并发能力，减少单机的数据量。
		架构变更，自己要参与进来，才有收获。
		
    第三阶段
		索引个数的优化
			大表的7个二级索引，优化到了4个二级索引，加快了查询频率很高的SQL语句的执行速度。
			1. 要理解索引的原理，通过调整索引的顺序，维护更少的索引；
			2. 结合业务场景，比如查询频率很低的SQL语句，没必要建3个列的联合索引
			3. 举一反三：表超过5个索引，加入每天的巡检项中。
			4. RDS是做不到这个的。
